{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cats vs Dogs\n",
    "\n",
    "The purpose of this is to train a convnet from scratch using a small dataset. The data is from the Kaggle website and was a competition ran around September 2013.\n",
    "\n",
    "## Extract the images from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process skipped as content exists.\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "import keras\n",
    "\n",
    "original_dataset_dir = '/Users/datascience4/Downloads/kaggle_cats_and_dogs/train'\n",
    "\n",
    "#new directory for a smaller dataset than what is packed in kaggle dataset.\n",
    "base_dir = '/Users/datascience4/Documents/cats_and_dogs_small'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "test_cats_dir = os.path.join(test_dir, 'cats')\n",
    "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "## training set for the training validation and test splits\n",
    "## this will be broken down as:\n",
    "## training set 1000 samples (images) of each class (2000 total)\n",
    "## validation set of 500 samples (images) of each class (1000 total)\n",
    "## test set of 500 samples (images) of each class (1000 total)\n",
    "\n",
    "try:\n",
    "    os.mkdir(base_dir)\n",
    "    #make the train test and validation directories.\n",
    "    os.mkdir(train_dir)\n",
    "    os.mkdir(test_dir)\n",
    "    os.mkdir(validation_dir)\n",
    "    os.mkdir(train_cats_dir)\n",
    "    os.mkdir(train_dogs_dir)\n",
    "    os.mkdir(test_cats_dir)\n",
    "    os.mkdir(test_dogs_dir)\n",
    "    os.mkdir(validation_cats_dir)\n",
    "    os.mkdir(validation_dogs_dir)\n",
    "    \n",
    "except FileExistsError:\n",
    "    \n",
    "    print('Process skipped as content exists.')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take the files in the folder and put them into train, validation, and test the respective files\n",
    "## using list comprehensions in a fast way to match the format on the files\n",
    "## f is short hand new in 3.6 python pep498 formatted string literals\n",
    "\n",
    "# training cats directory\n",
    "fnames = [f'cat.{i}.jpg' for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dest = os.path.join(train_cats_dir, fname)\n",
    "    shutil.copyfile(src, dest)\n",
    "\n",
    "# test cats directory\n",
    "fnames = [f'cat.{i}.jpg' for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dest = os.path.join(test_cats_dir, fname)\n",
    "    shutil.copyfile(src, dest)\n",
    "\n",
    "# validation cats directory\n",
    "fnames = [f'cat.{i}.jpg' for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dest = os.path.join(validation_cats_dir, fname)\n",
    "    shutil.copyfile(src, dest)\n",
    "\n",
    "#training dogs directory\n",
    "fnames = [f'dog.{i}.jpg' for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dest = os.path.join(train_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dest)\n",
    "\n",
    "#test dogs directory\n",
    "fnames = [f'dog.{i}.jpg' for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dest = os.path.join(test_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dest)\n",
    "    \n",
    "#validation dogs directory\n",
    "fnames = [f'dog.{i}.jpg' for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dest = os.path.join(validation_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training cat images 1000\n",
      "total test cat images 500\n",
      "total validation cat images 500\n",
      "total training dog images 1000\n",
      "total test dog images 500\n",
      "total validation dog images 500\n"
     ]
    }
   ],
   "source": [
    "print('total training cat images', len(os.listdir(train_cats_dir)))\n",
    "print('total test cat images', len(os.listdir(test_cats_dir)))\n",
    "print('total validation cat images', len(os.listdir(validation_cats_dir)))\n",
    "print('total training dog images', len(os.listdir(train_dogs_dir)))\n",
    "print('total test dog images', len(os.listdir(test_dogs_dir)))\n",
    "print('total validation dog images', len(os.listdir(validation_dogs_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting the convnet on a binary classification problem.\n",
    "\n",
    "Because these images are bigger an the a more complex problem then MNIST digits, an additional Conv2D and Maxpooling will need to be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 15, 15, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 3,453,121\n",
      "Trainable params: 3,453,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers, models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "         input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "## from the second layer, input shape is assumed from the first layer\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## if this goes into a different environment other than a notebook\n",
    "## it is typical to import earlier than this.\n",
    "from keras import optimizers\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x11fa51978>\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "?model.compile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "The next thing to do is data preprocessing, since images are currently in jpeg they need to be reformatted into preprocessed floating point tensors before being fed into the network.\n",
    "\n",
    "* Read the picture file\n",
    "* Decode the jpeg content to RGB grids of pixels.\n",
    "* Convert these into floating-point tensors.\n",
    "* Rescale the pixel values (between 0 and 255) to the \\[0, 1\\] interval (neural networks prefer to deal with small input values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# ?ImageDataGenerator\n",
    "\n",
    "## rescale all images by 1/255\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(150, 150), #Re size all images to 150 x 150\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data batch shape: (20, 150, 150, 3)\n",
      "labels batch shape: (20,)\n"
     ]
    }
   ],
   "source": [
    "keras.__version__\n",
    "for data_batch, labels_batch in train_generator:\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.8196079 , 0.7686275 , 0.6431373 ],\n",
       "        [0.7372549 , 0.6745098 , 0.62352943],\n",
       "        [0.82745105, 0.7686275 , 0.7568628 ],\n",
       "        ...,\n",
       "        [0.8705883 , 0.7607844 , 0.7058824 ],\n",
       "        [0.73333335, 0.6784314 , 0.627451  ],\n",
       "        [0.9960785 , 1.        , 0.9803922 ]],\n",
       "\n",
       "       [[0.79215693, 0.7254902 , 0.62352943],\n",
       "        [0.9058824 , 0.8352942 , 0.78823537],\n",
       "        [0.90196085, 0.8235295 , 0.8196079 ],\n",
       "        ...,\n",
       "        [0.94117653, 0.81568635, 0.76470596],\n",
       "        [0.83921576, 0.76470596, 0.70980394],\n",
       "        [0.70980394, 0.69803923, 0.6784314 ]],\n",
       "\n",
       "       [[0.854902  , 0.7490196 , 0.68235296],\n",
       "        [0.90196085, 0.7960785 , 0.7607844 ],\n",
       "        [0.9058824 , 0.80392164, 0.8000001 ],\n",
       "        ...,\n",
       "        [0.89019614, 0.74509805, 0.68235296],\n",
       "        [0.83921576, 0.7294118 , 0.6862745 ],\n",
       "        [1.        , 0.9686275 , 0.9686275 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.9803922 , 0.9843138 , 0.96470594],\n",
       "        [0.95294124, 0.9568628 , 0.93725497],\n",
       "        [0.9333334 , 0.93725497, 0.9176471 ],\n",
       "        ...,\n",
       "        [1.        , 1.        , 0.9803922 ],\n",
       "        [0.96470594, 0.9686275 , 0.9450981 ],\n",
       "        [0.9960785 , 1.        , 0.97647065]],\n",
       "\n",
       "       [[1.        , 1.        , 0.9921569 ],\n",
       "        [0.9843138 , 0.9843138 , 0.97647065],\n",
       "        [0.8941177 , 0.8941177 , 0.8862746 ],\n",
       "        ...,\n",
       "        [0.9686275 , 0.9686275 , 0.9607844 ],\n",
       "        [0.9960785 , 0.9960785 , 0.98823535],\n",
       "        [0.9921569 , 0.9921569 , 0.9843138 ]],\n",
       "\n",
       "       [[0.95294124, 0.95294124, 0.9450981 ],\n",
       "        [1.        , 1.        , 0.9921569 ],\n",
       "        [0.9725491 , 0.9725491 , 0.96470594],\n",
       "        ...,\n",
       "        [0.9803922 , 0.9803922 , 0.9725491 ],\n",
       "        [0.9960785 , 0.9960785 , 0.98823535],\n",
       "        [0.9843138 , 0.9843138 , 0.97647065]]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
